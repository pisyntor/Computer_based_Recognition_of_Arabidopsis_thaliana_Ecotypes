{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e735983-b4b1-4cfd-97a4-841bd1d6cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.filters import gaussian, laplace\n",
    "from skimage.feature import hog, SIFT\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import histogram\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebf29f-999f-40e3-a410-2262515bcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "OUTPUT_DIR = './features'\n",
    "\n",
    "# This variable will control whether to force extraction even if a CSV file exists\n",
    "FORCE_EXTRACT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e41e7-0412-4e72-a845-62b067b6b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory structure assumed is ./data/{dataset}/{class}/{replicate}/\n",
    "base_directory = Path(DATA_PATH)\n",
    "\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f825eb6-a352-4907-a2d1-7c05a01b9658",
   "metadata": {},
   "source": [
    "## Helper functions for I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c651d4d-8c3b-42ef-bc59-1d6969cf1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df: pd.DataFrame, csv_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame into a CSV file after converting feature columns into individual feature columns.\n",
    "    \"\"\"\n",
    "    new_df = {col:df[col] for col in df.columns if col not in ['hog', 'log', 'vgg', 'resnet']}\n",
    "    hog_feats = np.array([feat for feat in df['hog']])\n",
    "    log_feats = np.array([feat for feat in df['log']])\n",
    "    vgg_feats = np.array([feat for feat in df['vgg']])\n",
    "    resnet_feats = np.array([feat for feat in df['resnet']])\n",
    "    \n",
    "    \n",
    "    for idx in range(256):\n",
    "        new_df[f'hog_{idx}'] = hog_feats[:, idx]\n",
    "\n",
    "    for idx in range(256):\n",
    "        new_df[f'log_{idx}'] = log_feats[:, idx]\n",
    "\n",
    "    for idx in range(256):\n",
    "        new_df[f'vgg_{idx}'] = vgg_feats[:, idx]\n",
    "\n",
    "    for idx in range(256):\n",
    "        new_df[f'resnet_{idx}'] = resnet_feats[:, idx]\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "\n",
    "    new_df.to_csv(csv_path, index=False)\n",
    "\n",
    "def read_convert_csv(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, converts individual feature columns back into original feature columns and returns the DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    hog_cols = [f'hog_{idx}' for idx in range(256)]\n",
    "    log_cols = [f'log_{idx}' for idx in range(256)]\n",
    "    vgg_cols = [f'vgg_{idx}' for idx in range(256)]\n",
    "    resnet_cols = [f'resnet_{idx}' for idx in range(256)]\n",
    "\n",
    "    df['hog'] = [feat for feat in df[hog_cols].to_numpy()]\n",
    "    df['log'] = [feat for feat in df[log_cols].to_numpy()]\n",
    "    df['vgg'] = [feat for feat in df[vgg_cols].to_numpy()]\n",
    "    df['resnet'] = [feat for feat in df[resnet_cols].to_numpy()]\n",
    "\n",
    "\n",
    "    df = df.drop(hog_cols+log_cols+vgg_cols+resnet_cols, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e13a5c-9d02-4ef4-a0da-b5d6fed83d15",
   "metadata": {},
   "source": [
    "## Feature extractor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbba0f0-71fa-4cb1-8fcf-6f003177c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexityFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes feature extractors and preprocessing tools.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize SIFT extractor\n",
    "        self.sift_extractor = SIFT()\n",
    "        \n",
    "        # Setting up VGG16 and ResNet50 for feature extraction\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else self.device)\n",
    "        self.vgg_model = models.vgg16(weights='VGG16_Weights.DEFAULT').features.to(self.device).eval()\n",
    "        resnet_model = models.resnet50(weights='ResNet50_Weights.DEFAULT').to(self.device)\n",
    "        self.resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1])).eval()\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def color_modes(self, img: np.array) -> int:\n",
    "        \"\"\"\n",
    "        1. Determining the number of mean plus 2*sigma modes present in the color distribution.\n",
    "        \n",
    "        Compute the number of modes based on color mean and standard deviation.\n",
    "        \"\"\"\n",
    "        color_mean = np.mean(img, axis=(0, 1))\n",
    "        color_std = np.std(img, axis=(0, 1))\n",
    "        upper_bound = color_mean + 2 * color_std\n",
    "        lower_bound = color_mean - 2 * color_std\n",
    "        return np.sum((img > lower_bound) & (img < upper_bound))\n",
    "\n",
    "    def rank_unique_colors(self, img: np.array, delta: int = 10) -> int:\n",
    "        \"\"\"\n",
    "        2. Rank the number of unique colors present in the image that differ by a minimum delta.\n",
    "        \"\"\"\n",
    "        unique_colors, counts = np.unique(img.reshape(-1, 3), axis=0, return_counts=True)\n",
    "        significant_colors = [color for color, count in zip(unique_colors, counts) if count > delta]\n",
    "        return len(significant_colors)\n",
    "\n",
    "    def spectral_peaks(self, img: np.array) -> int:\n",
    "        \"\"\"\n",
    "        3. Compute the Spectral distribution on each axis and compute the number of mean plus 2 * sigma spectral peaks.\n",
    "        Calculate spectral peaks using Fourier Transform.\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = rgb2gray(img)\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = np.abs(fshift)\n",
    "        mean_val = np.mean(magnitude_spectrum)\n",
    "        std_val = np.std(magnitude_spectrum)\n",
    "        peaks, _ = find_peaks(magnitude_spectrum.flatten(), height=(mean_val + 2 * std_val))\n",
    "        return len(peaks)\n",
    "\n",
    "    def pixel_intensity_entropy(self, img: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the entropy of pixel intensity for a grayscale image.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Flatten the image and compute histogram\n",
    "        hist = self.compute_histogram(img.flatten())\n",
    "        \n",
    "        # Compute entropy\n",
    "        e = entropy(hist)\n",
    "        return e\n",
    "\n",
    "    def log_features(self, img: np.array, sigma: float = 1.0) -> np.array:\n",
    "        \"\"\"\n",
    "        6. LoG filters\n",
    "        Compute the Laplacian of Gaussian for an image.\n",
    "        \"\"\"\n",
    "        gray = rgb2gray(img)\n",
    "        # Apply Gaussian blur\n",
    "        blurred = gaussian(gray, sigma=sigma)\n",
    "        # Compute Laplacian\n",
    "        log = laplace(blurred)\n",
    "        return log\n",
    "\n",
    "    def hog_features(self, img: np.array) -> tuple:\n",
    "        \"\"\"\n",
    "        4. HoG\n",
    "        Extract Histogram of Oriented Gradients features.\n",
    "        \"\"\"\n",
    "        gray = rgb2gray(img)\n",
    "        features, hog_img = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "        return features, hog_img\n",
    "        \n",
    "    def sift_features(self, img: np.array) -> tuple:\n",
    "        \"\"\"\n",
    "        5. SIFT\n",
    "        Extract SIFT features.\n",
    "        \"\"\"\n",
    "        gray = rgb2gray(img)\n",
    "        self.sift_extractor.detect_and_extract(gray)\n",
    "        keypoints = self.sift_extractor.keypoints\n",
    "        descriptors = self.sift_extractor.descriptors\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    def vgg16_features(self, img: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        7. VGG16\n",
    "        Extract VGG16 features.\n",
    "        \"\"\"\n",
    "        img = Image.fromarray(img)\n",
    "        img_tensor = self.preprocess(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            features = self.vgg_model(img_tensor)\n",
    "        return features.cpu().numpy().flatten()\n",
    "        \n",
    "    def resnet_features(self, img: np.array) -> np.array:\n",
    "            \"\"\"\n",
    "            Extract features using ResNet50.\n",
    "            \"\"\"\n",
    "            \n",
    "            img = Image.fromarray(img)\n",
    "            img_tensor = self.preprocess(img).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                features = self.resnet_model(img_tensor)\n",
    "            return features.cpu().numpy().flatten()\n",
    "\n",
    "    @classmethod\n",
    "    def feat2hist(cls, arr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Convert a feature array to a histogram.\n",
    "        \"\"\"\n",
    "        normalized_arr = cls.normalize_array(arr)\n",
    "        hist = cls.compute_histogram(normalized_arr.astype(np.uint8))\n",
    "        return hist\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_histogram(arr: np.array, bins: int = 256) -> np.array:\n",
    "        \"\"\"\n",
    "        Compute histogram of an array.\n",
    "        \"\"\"\n",
    "        hist, centers = histogram(arr.flatten(), nbins=bins, source_range='dtype')\n",
    "        assert (centers == np.arange(256)).all()\n",
    "        return hist\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_array(arr: np.array, new_min: float = 0, new_max: float = 255) -> np.array:\n",
    "        \"\"\"\n",
    "        Normalize an array to a new specified min and max value.\n",
    "        \"\"\"\n",
    "        old_min, old_max = np.min(arr), np.max(arr)\n",
    "        normalized_arr = (arr - old_min) / (old_max - old_min) * (new_max - new_min) + new_min\n",
    "        return normalized_arr\n",
    "\n",
    "    def extract_all_features(self, img_path: str) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Extract all features and return them as a row for a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        # Read the image\n",
    "        img = np.array(Image.open(img_path))\n",
    "\n",
    "        # Extract features\n",
    "        color_modes_val = self.color_modes(img)\n",
    "        rank_colors = self.rank_unique_colors(img)\n",
    "        spectral = self.spectral_peaks(img)\n",
    "        sift_keypoints, sift_descriptors = self.sift_features(img)\n",
    "        pixel_entropy = self.pixel_intensity_entropy(img)\n",
    "        hog_feats, hog_img = self.hog_features(img)\n",
    "        hog_hist = self.feat2hist(hog_feats)\n",
    "        log_feats = self.log_features(img)\n",
    "        log_hist = self.feat2hist(log_feats)\n",
    "        vgg_feats = self.vgg16_features(img)\n",
    "        vgg_hist = self.feat2hist(vgg_feats)\n",
    "        resnet_feats = self.resnet_features(img)\n",
    "        resnet_hist = self.feat2hist(resnet_feats)\n",
    "        \n",
    "        # Collate features into a dictionary\n",
    "        data = {\n",
    "            \"filename\": img_path.name,\n",
    "            \"dataset\": img_path.parent.parent.parent.name,\n",
    "            \"class\": img_path.parent.parent.name,\n",
    "            \"replicate\": img_path.parent.name,            \n",
    "            \"color_modes\": color_modes_val,\n",
    "            \"rank_colors\": rank_colors,\n",
    "            \"spectral\": spectral,\n",
    "            \"sift\": len(sift_keypoints),\n",
    "            \"pixel_entropy\": pixel_entropy,\n",
    "            \"log\": log_hist,\n",
    "            \"hog\": hog_hist,\n",
    "            \"vgg\": vgg_hist,\n",
    "            \"resnet\":resnet_hist\n",
    "        }\n",
    "        \n",
    "        return pd.Series(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a16ad-c90d-47a8-99d5-2d810c656646",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417511ef-ce13-4052-bfcc-e9fdda0791ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ComplexityFeatureExtractor()\n",
    "\n",
    "# Get list of datasets\n",
    "datasets = sorted([ds for ds in base_directory.iterdir() if ds.is_dir()])\n",
    "for dataset in tqdm(datasets, desc=\"Datasets\", position=0, leave=True):\n",
    "    # Iterate over classes within each dataset\n",
    "    classes = sorted([g for g in dataset.iterdir() if g.is_dir()])\n",
    "    \n",
    "    for class_ in tqdm(classes, desc=f\"Classes in {dataset.name}\", position=1, leave=False):\n",
    "        # Iterate over replicates within each class\n",
    "        replicates = sorted([rep for rep in class_.iterdir() if rep.is_dir()])\n",
    "        \n",
    "        for replicate in tqdm(replicates, desc=f\"Replicates in {class_.name}\", position=2, leave=False):\n",
    "            \n",
    "            # If the CSV file already exists and FORCE_EXTRACT is False, skip this replicate\n",
    "            if Path(csv_filename).exists() and not FORCE_EXTRACT:\n",
    "                # print(f\"Skipping extraction for {csv_filename} as it already exists.\")\n",
    "                continue\n",
    "            \n",
    "\n",
    "            img_list = list(replicate.glob('*.png'))\n",
    "            if len(img_list) == 0:\n",
    "                continue\n",
    "\n",
    "            csv_filename = output_dir.joinpath(dataset.name, class_.name, f\"{replicate.name}.csv\")\n",
    "            if not csv_filename.parent.exists():\n",
    "                csv_filename.parent.mkdir(parents=True)\n",
    "                \n",
    "            all_feats = []\n",
    "            for img_path in tqdm(img_list, desc=f\"Extracting from {replicate.name}\", position=3, leave=False):\n",
    "                features_series = extractor.extract_all_features(img_path)\n",
    "                all_feats.append(features_series)\n",
    "\n",
    "\n",
    "\n",
    "            df = pd.concat(all_feats, axis=1).T\n",
    "            df['hog_entropy'] = df['hog'].apply(entropy)\n",
    "            df['log_entropy'] = df['log'].apply(entropy)\n",
    "            df['vgg_entropy'] = df['vgg'].apply(entropy)\n",
    "            df['resnet_entropy'] = df['resnet'].apply(entropy)\n",
    "\n",
    "            # Save using the desired naming format\n",
    "            save_to_csv(df, csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1719a8-f5f2-40d6-82f5-f641923991ce",
   "metadata": {},
   "source": [
    "## Combine csv files into one & validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ab474-eb93-44c4-8cff-3eece2239bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    'color_modes': 'Color distribution modes',\n",
    "    'rank_colors': 'Rank #unique colors',\n",
    "    'spectral': 'Spectral distribution modes',\n",
    "    'sift': 'SIFT',\n",
    "    'pixel_entropy': 'Pixel entropy',\n",
    "    'hog_entropy': 'HoG',\n",
    "    'log_entropy': 'LoG',\n",
    "    'vgg_entropy': 'VGG16',\n",
    "    'resnet_entropy': 'ResNet50',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b585ed0-74cf-4677-bb3e-1b8b85f9dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all csv files\n",
    "csv_files = []\n",
    "for csv_file in output_dir.rglob('*.csv'):\n",
    "    csv_files.append(read_convert_csv(csv_file))\n",
    "\n",
    "# Concatenate csv files\n",
    "df_final = pd.concat(csv_files)\n",
    "\n",
    "# Rename columns\n",
    "df_final = df_final.rename(rename_columns, axis=1)\n",
    "\n",
    "# Sort based on dataset, class and replicate\n",
    "df_final = df_final.sort_values(['dataset', 'class', 'replicate'], axis=0)\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19d18f-2ca4-4f2c-8cba-45f175db5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we processed all png files.\n",
    "len(list(base_directory.rglob('*.png'))),len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362c242-e04a-4a68-9f00-09285a370bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(df_final, output_dir.parent.joinpath('all_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5ee04-92dc-4325-89cb-538a592a98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that we can save and load the csv file correctly.\n",
    "df_validate = read_convert_csv(output_dir.parent.joinpath('all_features.csv'))\n",
    "df_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cee844-e040-40d9-ac13-58f90c9cf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate.drop(['hog', 'log', 'vgg', 'resnet'], axis=1).to_csv(output_dir.parent.joinpath('all_features_truncated.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fb20e-1ece-4a4f-b435-4a2b516fe3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate_truncated = pd.read_csv(output_dir.parent.joinpath('all_features_truncated.csv'))\n",
    "df_validate_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c07e07-ea58-4e62-8352-eb9f8065bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate_truncated.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
